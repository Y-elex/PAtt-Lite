{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afba9042",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:04.363918Z",
     "iopub.status.busy": "2024-04-05T03:08:04.359563Z",
     "iopub.status.idle": "2024-04-05T03:08:09.251117Z",
     "shell.execute_reply": "2024-04-05T03:08:09.250372Z",
     "shell.execute_reply.started": "2024-04-05T03:06:26.029431Z"
    },
    "papermill": {
     "duration": 4.906285,
     "end_time": "2024-04-05T03:08:09.251280",
     "exception": false,
     "start_time": "2024-04-05T03:08:04.344995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe0490b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:09.268693Z",
     "iopub.status.busy": "2024-04-05T03:08:09.267799Z",
     "iopub.status.idle": "2024-04-05T03:08:09.270493Z",
     "shell.execute_reply": "2024-04-05T03:08:09.269879Z",
     "shell.execute_reply.started": "2024-04-05T03:06:31.268251Z"
    },
    "papermill": {
     "duration": 0.013423,
     "end_time": "2024-04-05T03:08:09.270616",
     "exception": false,
     "start_time": "2024-04-05T03:08:09.257193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "IMG_SHAPE = (120, 120, 3)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "TRAIN_EPOCH = 100\n",
    "TRAIN_LR = 1e-3\n",
    "TRAIN_ES_PATIENCE = 5\n",
    "TRAIN_LR_PATIENCE = 3\n",
    "TRAIN_MIN_LR = 1e-6\n",
    "TRAIN_DROPOUT = 0.1\n",
    "\n",
    "FT_EPOCH = 500\n",
    "FT_LR = 1e-5\n",
    "FT_LR_DECAY_STEP = 80.0\n",
    "FT_LR_DECAY_RATE = 1\n",
    "FT_ES_PATIENCE = 20\n",
    "FT_DROPOUT = 0.2\n",
    "\n",
    "ES_LR_MIN_DELTA = 0.003\n",
    "train_acc_list = []\n",
    "val_acc_list = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "epoch_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d318d802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:09.298321Z",
     "iopub.status.busy": "2024-04-05T03:08:09.297711Z",
     "iopub.status.idle": "2024-04-05T03:08:21.833062Z",
     "shell.execute_reply": "2024-04-05T03:08:21.832391Z",
     "shell.execute_reply.started": "2024-04-05T03:06:31.275621Z"
    },
    "papermill": {
     "duration": 12.557677,
     "end_time": "2024-04-05T03:08:21.833202",
     "exception": false,
     "start_time": "2024-04-05T03:08:09.275525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_sample: (66379, 120, 120, 3)\n",
      "Shape of train_label: (66379,)\n",
      "Shape of valid_sample: (8341, 120, 120, 3)\n",
      "Shape of valid_label: (8341,)\n",
      "Shape of test_sample: (3573, 120, 120, 3)\n",
      "Shape of test_label: (3573,)\n"
     ]
    }
   ],
   "source": [
    "# Load your data here, PAtt-Lite was trained with h5py for shorter loading time\n",
    "with h5py.File('ferp.h5', 'r') as f:\n",
    "    X_train = f['X_train'][:]  # 形状 (N, 120, 120, 3)\n",
    "    y_train = f['y_train'][:]  # 形状 (N,)\n",
    "    X_valid = f['X_val'][:]      # 验证集\n",
    "    y_valid = f['y_val'][:]      # 验证集标签\n",
    "    X_test = f['X_test'][:]    # 测试集\n",
    "    y_test = f['y_test'][:]    # 测试集标签\n",
    "\n",
    "print(\"Shape of train_sample: {}\".format(X_train.shape))\n",
    "print(\"Shape of train_label: {}\".format(y_train.shape))\n",
    "print(\"Shape of valid_sample: {}\".format(X_valid.shape))\n",
    "print(\"Shape of valid_label: {}\".format(y_valid.shape))\n",
    "print(\"Shape of test_sample: {}\".format(X_test.shape))\n",
    "print(\"Shape of test_label: {}\".format(y_test.shape))\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e772bf90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:21.872945Z",
     "iopub.status.busy": "2024-04-05T03:08:21.872214Z",
     "iopub.status.idle": "2024-04-05T04:11:01.037919Z",
     "shell.execute_reply": "2024-04-05T04:11:01.038380Z",
     "shell.execute_reply.started": "2024-04-05T03:06:43.580536Z"
    },
    "papermill": {
     "duration": 3759.199616,
     "end_time": "2024-04-05T04:11:01.038616",
     "exception": false,
     "start_time": "2024-04-05T03:08:21.839000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 39ms/step - accuracy: 0.5194 - loss: 1.3061 - val_accuracy: 0.6437 - val_loss: 1.1189 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 47ms/step - accuracy: 0.7290 - loss: 0.7826 - val_accuracy: 0.6144 - val_loss: 1.5102 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 45ms/step - accuracy: 0.7768 - loss: 0.6479 - val_accuracy: 0.6667 - val_loss: 1.2907 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 42ms/step - accuracy: 0.8060 - loss: 0.5623 - val_accuracy: 0.6517 - val_loss: 1.4400 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 40ms/step - accuracy: 0.8264 - loss: 0.5080 - val_accuracy: 0.6693 - val_loss: 1.2613 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 38ms/step - accuracy: 0.8441 - loss: 0.4492 - val_accuracy: 0.6665 - val_loss: 1.3106 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 44ms/step - accuracy: 0.8770 - loss: 0.3590 - val_accuracy: 0.6656 - val_loss: 1.5093 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 56ms/step - accuracy: 0.8934 - loss: 0.3092 - val_accuracy: 0.6701 - val_loss: 1.5942 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 61ms/step - accuracy: 0.8979 - loss: 0.2954 - val_accuracy: 0.6645 - val_loss: 1.6514 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 63ms/step - accuracy: 0.9033 - loss: 0.2809 - val_accuracy: 0.6675 - val_loss: 1.6882 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 66ms/step - accuracy: 0.9086 - loss: 0.2631 - val_accuracy: 0.6671 - val_loss: 1.7090 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 67ms/step - accuracy: 0.9111 - loss: 0.2595 - val_accuracy: 0.6649 - val_loss: 1.7400 - learning_rate: 1.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m604s\u001b[0m 73ms/step - accuracy: 0.9146 - loss: 0.2485 - val_accuracy: 0.6674 - val_loss: 1.7125 - learning_rate: 1.0000e-05\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 189ms/step - accuracy: 0.7202 - loss: 1.0418\n",
      "\n",
      "Finetuning ...\n",
      "Epoch 9/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 73ms/step - accuracy: 0.8694 - loss: 0.4014 - val_accuracy: 0.6715 - val_loss: 1.5074\n",
      "Epoch 10/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 72ms/step - accuracy: 0.8695 - loss: 0.4017 - val_accuracy: 0.6710 - val_loss: 1.5347\n",
      "Epoch 11/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 73ms/step - accuracy: 0.8677 - loss: 0.3994 - val_accuracy: 0.6703 - val_loss: 1.5609\n",
      "Epoch 12/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 73ms/step - accuracy: 0.8683 - loss: 0.3995 - val_accuracy: 0.6714 - val_loss: 1.5269\n",
      "Epoch 13/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 74ms/step - accuracy: 0.8666 - loss: 0.4008 - val_accuracy: 0.6705 - val_loss: 1.5268\n",
      "Epoch 14/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m631s\u001b[0m 76ms/step - accuracy: 0.8690 - loss: 0.3995 - val_accuracy: 0.6702 - val_loss: 1.5328\n",
      "Epoch 15/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 76ms/step - accuracy: 0.8696 - loss: 0.3996 - val_accuracy: 0.6708 - val_loss: 1.5433\n",
      "Epoch 16/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 79ms/step - accuracy: 0.8726 - loss: 0.3928 - val_accuracy: 0.6709 - val_loss: 1.5339\n",
      "Epoch 17/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 80ms/step - accuracy: 0.8684 - loss: 0.3997 - val_accuracy: 0.6696 - val_loss: 1.5453\n",
      "Epoch 18/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m673s\u001b[0m 81ms/step - accuracy: 0.8717 - loss: 0.3936 - val_accuracy: 0.6689 - val_loss: 1.5488\n",
      "Epoch 19/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m700s\u001b[0m 84ms/step - accuracy: 0.8744 - loss: 0.3930 - val_accuracy: 0.6708 - val_loss: 1.5419\n",
      "Epoch 20/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m755s\u001b[0m 91ms/step - accuracy: 0.8691 - loss: 0.3992 - val_accuracy: 0.6714 - val_loss: 1.5253\n",
      "Epoch 21/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 89ms/step - accuracy: 0.8712 - loss: 0.3928 - val_accuracy: 0.6702 - val_loss: 1.5557\n",
      "Epoch 22/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m772s\u001b[0m 93ms/step - accuracy: 0.8685 - loss: 0.4010 - val_accuracy: 0.6722 - val_loss: 1.5119\n",
      "Epoch 23/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m764s\u001b[0m 92ms/step - accuracy: 0.8695 - loss: 0.3957 - val_accuracy: 0.6703 - val_loss: 1.5354\n",
      "Epoch 24/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 95ms/step - accuracy: 0.8729 - loss: 0.3949 - val_accuracy: 0.6707 - val_loss: 1.5311\n",
      "Epoch 25/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 93ms/step - accuracy: 0.8707 - loss: 0.3971 - val_accuracy: 0.6708 - val_loss: 1.5361\n",
      "Epoch 26/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m786s\u001b[0m 95ms/step - accuracy: 0.8682 - loss: 0.3963 - val_accuracy: 0.6715 - val_loss: 1.5190\n",
      "Epoch 27/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m818s\u001b[0m 99ms/step - accuracy: 0.8675 - loss: 0.4048 - val_accuracy: 0.6696 - val_loss: 1.5330\n",
      "Epoch 28/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 100ms/step - accuracy: 0.8664 - loss: 0.4073 - val_accuracy: 0.6709 - val_loss: 1.5188\n",
      "Epoch 29/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m843s\u001b[0m 102ms/step - accuracy: 0.8703 - loss: 0.3968 - val_accuracy: 0.6709 - val_loss: 1.5392\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 217ms/step - accuracy: 0.7208 - loss: 1.0090\n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "input_layer = tf.keras.Input(shape=IMG_SHAPE, name='universal_input')\n",
    "sample_resizing = tf.keras.layers.Resizing(224, 224, name=\"resize\")\n",
    "data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(mode='horizontal'), \n",
    "                                        tf.keras.layers.RandomContrast(factor=0.3)], name=\"augmentation\")\n",
    "preprocess_input = tf.keras.applications.mobilenet.preprocess_input\n",
    "\n",
    "backbone = tf.keras.applications.mobilenet.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "backbone.trainable = False\n",
    "base_model = tf.keras.Model(backbone.input, backbone.layers[-29].output, name='base_model')\n",
    "\n",
    "self_attention = tf.keras.layers.Attention(use_scale=True, name='attention')\n",
    "patch_extraction = tf.keras.Sequential([\n",
    "    tf.keras.layers.SeparableConv2D(256, kernel_size=4, strides=4, padding='same', activation='relu'), \n",
    "    tf.keras.layers.SeparableConv2D(256, kernel_size=2, strides=2, padding='valid', activation='relu'), \n",
    "    tf.keras.layers.Conv2D(256, kernel_size=1, strides=1, padding='valid', activation='relu')\n",
    "], name='patch_extraction')\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D(name='gap')\n",
    "pre_classification = tf.keras.Sequential([tf.keras.layers.Dense(32, activation='relu'), \n",
    "                                          tf.keras.layers.BatchNormalization()], name='pre_classification')\n",
    "prediction_layer = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name='classification_head')\n",
    "\n",
    "inputs = input_layer\n",
    "x = sample_resizing(inputs)\n",
    "x = data_augmentation(x)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = patch_extraction(x)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(TRAIN_DROPOUT)(x)\n",
    "x = pre_classification(x)\n",
    "#x_exp = tf.keras.layers.Lambda(lambda t: tf.expand_dims(t, axis=1))(x)\n",
    "#x_attn = self_attention([x_exp, x_exp])\n",
    "#x = tf.keras.layers.Lambda(lambda t: tf.squeeze(t, axis=1))(x_attn)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs, name='train-head')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=TRAIN_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training Procedure\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=TRAIN_ES_PATIENCE, min_delta=ES_LR_MIN_DELTA, restore_best_weights=True)\n",
    "learning_rate_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=TRAIN_LR_PATIENCE, verbose=0, min_delta=ES_LR_MIN_DELTA, min_lr=TRAIN_MIN_LR)\n",
    "history = model.fit(X_train, y_train, epochs=TRAIN_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=1, \n",
    "                    class_weight=class_weights, callbacks=[early_stopping_callback, learning_rate_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Model Finetuning\n",
    "print(\"\\nFinetuning ...\")\n",
    "unfreeze = 59\n",
    "base_model.trainable = True\n",
    "fine_tune_from = len(base_model.layers) - unfreeze\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_from:]:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "inputs = input_layer\n",
    "x = sample_resizing(inputs)\n",
    "x = data_augmentation(x)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = patch_extraction(x)\n",
    "x = tf.keras.layers.SpatialDropout2D(FT_DROPOUT)(x)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n",
    "x = pre_classification(x)\n",
    "# 注意这里改为和训练阶段一致的方式处理 attention\n",
    "#x_exp = tf.keras.layers.Lambda(lambda t: tf.expand_dims(t, axis=1))(x)\n",
    "#x_attn = self_attention([x_exp, x_exp])\n",
    "#x = tf.keras.layers.Lambda(lambda t: tf.squeeze(t, axis=1))(x_attn)\n",
    "x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs, name='finetune-backbone')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=FT_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training Procedure\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=ES_LR_MIN_DELTA, patience=FT_ES_PATIENCE, restore_best_weights=True)\n",
    "scheduler = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=FT_LR, decay_steps=FT_LR_DECAY_STEP, decay_rate=FT_LR_DECAY_RATE)\n",
    "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(schedule=scheduler)\n",
    "# 用调度器初始化优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
    "\n",
    "# 重新编译模型（微调阶段通常会重新编译）\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_finetune = model.fit(X_train, y_train, epochs=FT_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=1, \n",
    "                             initial_epoch=history.epoch[-TRAIN_ES_PATIENCE], callbacks=[early_stopping_callback, tensorboard_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "model.save('model_FERP.keras')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1718596,
     "sourceId": 5546170,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3788.698907,
   "end_time": "2024-04-05T04:11:04.022881",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-05T03:07:55.323974",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
