{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afba9042",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:04.363918Z",
     "iopub.status.busy": "2024-04-05T03:08:04.359563Z",
     "iopub.status.idle": "2024-04-05T03:08:09.251117Z",
     "shell.execute_reply": "2024-04-05T03:08:09.250372Z",
     "shell.execute_reply.started": "2024-04-05T03:06:26.029431Z"
    },
    "papermill": {
     "duration": 4.906285,
     "end_time": "2024-04-05T03:08:09.251280",
     "exception": false,
     "start_time": "2024-04-05T03:08:04.344995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfe0490b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:09.268693Z",
     "iopub.status.busy": "2024-04-05T03:08:09.267799Z",
     "iopub.status.idle": "2024-04-05T03:08:09.270493Z",
     "shell.execute_reply": "2024-04-05T03:08:09.269879Z",
     "shell.execute_reply.started": "2024-04-05T03:06:31.268251Z"
    },
    "papermill": {
     "duration": 0.013423,
     "end_time": "2024-04-05T03:08:09.270616",
     "exception": false,
     "start_time": "2024-04-05T03:08:09.257193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "IMG_SHAPE = (120, 120, 3)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "TRAIN_EPOCH = 100\n",
    "TRAIN_LR = 1e-3\n",
    "TRAIN_ES_PATIENCE = 5\n",
    "TRAIN_LR_PATIENCE = 3\n",
    "TRAIN_MIN_LR = 1e-6\n",
    "TRAIN_DROPOUT = 0.1\n",
    "\n",
    "FT_EPOCH = 500\n",
    "FT_LR = 1e-5\n",
    "FT_LR_DECAY_STEP = 80.0\n",
    "FT_LR_DECAY_RATE = 1\n",
    "FT_ES_PATIENCE = 20\n",
    "FT_DROPOUT = 0.2\n",
    "\n",
    "ES_LR_MIN_DELTA = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d318d802",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:09.298321Z",
     "iopub.status.busy": "2024-04-05T03:08:09.297711Z",
     "iopub.status.idle": "2024-04-05T03:08:21.833062Z",
     "shell.execute_reply": "2024-04-05T03:08:21.832391Z",
     "shell.execute_reply.started": "2024-04-05T03:06:31.275621Z"
    },
    "papermill": {
     "duration": 12.557677,
     "end_time": "2024-04-05T03:08:21.833202",
     "exception": false,
     "start_time": "2024-04-05T03:08:09.275525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_sample: (66379, 120, 120, 3)\n",
      "Shape of train_label: (66379,)\n",
      "Shape of valid_sample: (8341, 120, 120, 3)\n",
      "Shape of valid_label: (8341,)\n",
      "Shape of test_sample: (3573, 120, 120, 3)\n",
      "Shape of test_label: (3573,)\n"
     ]
    }
   ],
   "source": [
    "# Load your data here, PAtt-Lite was trained with h5py for shorter loading time\n",
    "with h5py.File('ferp.h5', 'r') as f:\n",
    "    X_train = f['X_train'][:]  # 形状 (N, 120, 120, 3)\n",
    "    y_train = f['y_train'][:]  # 形状 (N,)\n",
    "    X_valid = f['X_val'][:]      # 验证集\n",
    "    y_valid = f['y_val'][:]      # 验证集标签\n",
    "    X_test = f['X_test'][:]    # 测试集\n",
    "    y_test = f['y_test'][:]    # 测试集标签\n",
    "\n",
    "print(\"Shape of train_sample: {}\".format(X_train.shape))\n",
    "print(\"Shape of train_label: {}\".format(y_train.shape))\n",
    "print(\"Shape of valid_sample: {}\".format(X_valid.shape))\n",
    "print(\"Shape of valid_label: {}\".format(y_valid.shape))\n",
    "print(\"Shape of test_sample: {}\".format(X_test.shape))\n",
    "print(\"Shape of test_label: {}\".format(y_test.shape))\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e772bf90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-05T03:08:21.872945Z",
     "iopub.status.busy": "2024-04-05T03:08:21.872214Z",
     "iopub.status.idle": "2024-04-05T04:11:01.037919Z",
     "shell.execute_reply": "2024-04-05T04:11:01.038380Z",
     "shell.execute_reply.started": "2024-04-05T03:06:43.580536Z"
    },
    "papermill": {
     "duration": 3759.199616,
     "end_time": "2024-04-05T04:11:01.038616",
     "exception": false,
     "start_time": "2024-04-05T03:08:21.839000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m822s\u001b[0m 99ms/step - accuracy: 0.5174 - loss: 1.3179 - val_accuracy: 0.5647 - val_loss: 1.5517 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m909s\u001b[0m 109ms/step - accuracy: 0.7308 - loss: 0.7792 - val_accuracy: 0.6346 - val_loss: 1.3078 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1372s\u001b[0m 165ms/step - accuracy: 0.7793 - loss: 0.6403 - val_accuracy: 0.6286 - val_loss: 1.3890 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m739s\u001b[0m 89ms/step - accuracy: 0.8030 - loss: 0.5718 - val_accuracy: 0.6515 - val_loss: 1.3570 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 66ms/step - accuracy: 0.8262 - loss: 0.5014 - val_accuracy: 0.6400 - val_loss: 1.5675 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 71ms/step - accuracy: 0.8410 - loss: 0.4600 - val_accuracy: 0.6569 - val_loss: 1.3983 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m809s\u001b[0m 97ms/step - accuracy: 0.8531 - loss: 0.4296 - val_accuracy: 0.6390 - val_loss: 1.5382 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1111s\u001b[0m 134ms/step - accuracy: 0.8648 - loss: 0.3956 - val_accuracy: 0.6648 - val_loss: 1.4418 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31357s\u001b[0m 4s/step - accuracy: 0.8720 - loss: 0.3694 - val_accuracy: 0.6463 - val_loss: 1.7579 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7759s\u001b[0m 935ms/step - accuracy: 0.8806 - loss: 0.3432 - val_accuracy: 0.6533 - val_loss: 1.6382 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m872s\u001b[0m 105ms/step - accuracy: 0.8874 - loss: 0.3284 - val_accuracy: 0.6289 - val_loss: 1.7598 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m911s\u001b[0m 110ms/step - accuracy: 0.9112 - loss: 0.2570 - val_accuracy: 0.6602 - val_loss: 1.6669 - learning_rate: 1.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m899s\u001b[0m 108ms/step - accuracy: 0.9269 - loss: 0.2134 - val_accuracy: 0.6655 - val_loss: 1.6894 - learning_rate: 1.0000e-04\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 237ms/step - accuracy: 0.7422 - loss: 0.9085\n",
      "\n",
      "Finetuning ...\n",
      "Epoch 9/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1015s\u001b[0m 122ms/step - accuracy: 0.8325 - loss: 0.5001 - val_accuracy: 0.6722 - val_loss: 1.4865\n",
      "Epoch 10/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m953s\u001b[0m 115ms/step - accuracy: 0.8390 - loss: 0.4887 - val_accuracy: 0.6715 - val_loss: 1.4906\n",
      "Epoch 11/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 100ms/step - accuracy: 0.8373 - loss: 0.4969 - val_accuracy: 0.6716 - val_loss: 1.4842\n",
      "Epoch 12/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m927s\u001b[0m 112ms/step - accuracy: 0.8394 - loss: 0.4887 - val_accuracy: 0.6738 - val_loss: 1.4481\n",
      "Epoch 13/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m986s\u001b[0m 119ms/step - accuracy: 0.8359 - loss: 0.4938 - val_accuracy: 0.6717 - val_loss: 1.4828\n",
      "Epoch 14/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m970s\u001b[0m 117ms/step - accuracy: 0.8426 - loss: 0.4797 - val_accuracy: 0.6715 - val_loss: 1.4912\n",
      "Epoch 15/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m894s\u001b[0m 108ms/step - accuracy: 0.8411 - loss: 0.4815 - val_accuracy: 0.6735 - val_loss: 1.4677\n",
      "Epoch 16/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m663s\u001b[0m 80ms/step - accuracy: 0.8377 - loss: 0.4895 - val_accuracy: 0.6715 - val_loss: 1.4934\n",
      "Epoch 17/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m647s\u001b[0m 78ms/step - accuracy: 0.8393 - loss: 0.4847 - val_accuracy: 0.6729 - val_loss: 1.4642\n",
      "Epoch 18/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m677s\u001b[0m 82ms/step - accuracy: 0.8420 - loss: 0.4792 - val_accuracy: 0.6725 - val_loss: 1.4776\n",
      "Epoch 19/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 82ms/step - accuracy: 0.8402 - loss: 0.4804 - val_accuracy: 0.6717 - val_loss: 1.4816\n",
      "Epoch 20/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 82ms/step - accuracy: 0.8399 - loss: 0.4822 - val_accuracy: 0.6725 - val_loss: 1.4856\n",
      "Epoch 21/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m699s\u001b[0m 84ms/step - accuracy: 0.8375 - loss: 0.4895 - val_accuracy: 0.6727 - val_loss: 1.4721\n",
      "Epoch 22/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m703s\u001b[0m 85ms/step - accuracy: 0.8395 - loss: 0.4860 - val_accuracy: 0.6719 - val_loss: 1.4767\n",
      "Epoch 23/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 87ms/step - accuracy: 0.8413 - loss: 0.4833 - val_accuracy: 0.6720 - val_loss: 1.4791\n",
      "Epoch 24/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 88ms/step - accuracy: 0.8404 - loss: 0.4816 - val_accuracy: 0.6719 - val_loss: 1.4684\n",
      "Epoch 25/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m737s\u001b[0m 89ms/step - accuracy: 0.8420 - loss: 0.4791 - val_accuracy: 0.6726 - val_loss: 1.4819\n",
      "Epoch 26/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 91ms/step - accuracy: 0.8397 - loss: 0.4857 - val_accuracy: 0.6720 - val_loss: 1.4596\n",
      "Epoch 27/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 93ms/step - accuracy: 0.8404 - loss: 0.4799 - val_accuracy: 0.6717 - val_loss: 1.4848\n",
      "Epoch 28/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m790s\u001b[0m 95ms/step - accuracy: 0.8410 - loss: 0.4808 - val_accuracy: 0.6721 - val_loss: 1.4964\n",
      "Epoch 29/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m823s\u001b[0m 99ms/step - accuracy: 0.8403 - loss: 0.4811 - val_accuracy: 0.6729 - val_loss: 1.4721\n",
      "Epoch 30/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m826s\u001b[0m 100ms/step - accuracy: 0.8373 - loss: 0.4860 - val_accuracy: 0.6734 - val_loss: 1.4987\n",
      "Epoch 31/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m836s\u001b[0m 101ms/step - accuracy: 0.8415 - loss: 0.4791 - val_accuracy: 0.6738 - val_loss: 1.4665\n",
      "Epoch 32/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m830s\u001b[0m 100ms/step - accuracy: 0.8356 - loss: 0.4962 - val_accuracy: 0.6720 - val_loss: 1.4735\n",
      "Epoch 33/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m838s\u001b[0m 101ms/step - accuracy: 0.8402 - loss: 0.4831 - val_accuracy: 0.6733 - val_loss: 1.4631\n",
      "Epoch 34/500\n",
      "\u001b[1m8298/8298\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m844s\u001b[0m 102ms/step - accuracy: 0.8391 - loss: 0.4887 - val_accuracy: 0.6715 - val_loss: 1.4990\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 218ms/step - accuracy: 0.7309 - loss: 0.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Model Building\n",
    "input_layer = tf.keras.Input(shape=IMG_SHAPE, name='universal_input')\n",
    "sample_resizing = tf.keras.layers.Resizing(224, 224, name=\"resize\")\n",
    "data_augmentation = tf.keras.Sequential([tf.keras.layers.RandomFlip(mode='horizontal'), \n",
    "                                        tf.keras.layers.RandomContrast(factor=0.3)], name=\"augmentation\")\n",
    "preprocess_input = tf.keras.applications.mobilenet.preprocess_input\n",
    "\n",
    "backbone = tf.keras.applications.mobilenet.MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "backbone.trainable = False\n",
    "base_model = tf.keras.Model(backbone.input, backbone.layers[-29].output, name='base_model')\n",
    "\n",
    "self_attention = tf.keras.layers.Attention(use_scale=True, name='attention')\n",
    "patch_extraction = tf.keras.Sequential([\n",
    "    tf.keras.layers.SeparableConv2D(256, kernel_size=4, strides=4, padding='same', activation='relu'), \n",
    "    tf.keras.layers.SeparableConv2D(256, kernel_size=2, strides=2, padding='valid', activation='relu'), \n",
    "    tf.keras.layers.Conv2D(256, kernel_size=1, strides=1, padding='valid', activation='relu')\n",
    "], name='patch_extraction')\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D(name='gap')\n",
    "pre_classification = tf.keras.Sequential([tf.keras.layers.Dense(32, activation='relu'), \n",
    "                                          tf.keras.layers.BatchNormalization()], name='pre_classification')\n",
    "prediction_layer = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name='classification_head')\n",
    "\n",
    "inputs = input_layer\n",
    "x = sample_resizing(inputs)\n",
    "x = data_augmentation(x)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = patch_extraction(x)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(TRAIN_DROPOUT)(x)\n",
    "x = pre_classification(x)\n",
    "x_exp = tf.keras.layers.Lambda(lambda t: tf.expand_dims(t, axis=1))(x)\n",
    "x_attn = self_attention([x_exp, x_exp])\n",
    "x = tf.keras.layers.Lambda(lambda t: tf.squeeze(t, axis=1))(x_attn)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs, name='train-head')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=TRAIN_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training Procedure\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=TRAIN_ES_PATIENCE, min_delta=ES_LR_MIN_DELTA, restore_best_weights=True)\n",
    "learning_rate_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=TRAIN_LR_PATIENCE, verbose=0, min_delta=ES_LR_MIN_DELTA, min_lr=TRAIN_MIN_LR)\n",
    "history = model.fit(X_train, y_train, epochs=TRAIN_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=1, \n",
    "                    class_weight=class_weights, callbacks=[early_stopping_callback, learning_rate_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Model Finetuning\n",
    "print(\"\\nFinetuning ...\")\n",
    "unfreeze = 59\n",
    "base_model.trainable = True\n",
    "fine_tune_from = len(base_model.layers) - unfreeze\n",
    "for layer in base_model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_from:]:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "inputs = input_layer\n",
    "x = sample_resizing(inputs)\n",
    "x = data_augmentation(x)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = patch_extraction(x)\n",
    "x = tf.keras.layers.SpatialDropout2D(FT_DROPOUT)(x)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n",
    "x = pre_classification(x)\n",
    "# 注意这里改为和训练阶段一致的方式处理 attention\n",
    "x_exp = tf.keras.layers.Lambda(lambda t: tf.expand_dims(t, axis=1))(x)\n",
    "x_attn = self_attention([x_exp, x_exp])\n",
    "x = tf.keras.layers.Lambda(lambda t: tf.squeeze(t, axis=1))(x_attn)\n",
    "x = tf.keras.layers.Dropout(FT_DROPOUT)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs, name='finetune-backbone')\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=FT_LR, global_clipnorm=3.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training Procedure\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=ES_LR_MIN_DELTA, patience=FT_ES_PATIENCE, restore_best_weights=True)\n",
    "scheduler = keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=FT_LR, decay_steps=FT_LR_DECAY_STEP, decay_rate=FT_LR_DECAY_RATE)\n",
    "scheduler_callback = tf.keras.callbacks.LearningRateScheduler(schedule=scheduler)\n",
    "# 用调度器初始化优化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
    "\n",
    "# 重新编译模型（微调阶段通常会重新编译）\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history_finetune = model.fit(X_train, y_train, epochs=FT_EPOCH, batch_size=BATCH_SIZE, validation_data=(X_valid, y_valid), verbose=1, \n",
    "                             initial_epoch=history.epoch[-TRAIN_ES_PATIENCE], callbacks=[early_stopping_callback, tensorboard_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1718596,
     "sourceId": 5546170,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3788.698907,
   "end_time": "2024-04-05T04:11:04.022881",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-05T03:07:55.323974",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
